#db_config.py

# config/db_config.py
MONGO_URI = "mongodb://localhost:27017/"
MONGO_DB = "interaction_db"
MONGO_COLLECTION = "aggregations"

#config/kafka_config.py

KAFKA_BROKER = "localhost:9092"
KAFKA_TOPIC = "user_interactions"

#dashboard/templates/index.html

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Dashboard</title>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
</head>
<body>
    <h1>üìä Real-Time User Interaction Dashboard</h1>
    <table border="1">
        <thead id="table-head">
            <tr>
                <th>Sequence Number</th>
                <th>Timestamp</th>
                <th>User ID</th>
                <th>Item ID</th>
                <th>Total Interactions</th>
                <th>Unique Items</th>
                <th>Processed Interactions</th>
                <th>Average Interactions</th>
            </tr>
        </thead>
        <tbody id="data-table"></tbody>
    </table>

    <script>
        function fetchMetrics() {
            $.getJSON("/metrics", function(data) {
                var tableBody = $("#data-table");
                tableBody.empty();

                data.forEach(row => {
                    let sequenceNumber = row.sequence_number || 0;
                    let timestamp = row.timestamp ? new Date(row.timestamp).toLocaleString() : 0;
                    let userId = row.user_id || 0;
                    let itemId = row.item_id || 0;
                    let totalInteractions = row.total_interactions || "";
                    let uniqueItems = row.unique_items ? row.unique_items.join(", ") : 0;
                    let processedInteractions = row.processed_interactions || 0;

                    // Calculate average interactions per item
                    let avgInteractions = (row.unique_items && row.unique_items.length > 0)
                        ? (row.total_interactions / row.unique_items.length).toFixed(2) 
                        : "";

                    tableBody.append(`
                        <tr>
                            <td>${sequenceNumber}</td>
                            <td>${timestamp}</td>
                            <td>${userId}</td>
                            <td>${itemId}</td>
                            <td>${totalInteractions}</td>
                            <td>${uniqueItems}</td>
                            <td>${processedInteractions}</td>
                            <td>${avgInteractions}</td>
                        </tr>
                    `);
                });
            });
        }

        setInterval(fetchMetrics, 3000);  // Auto-refresh every 3 seconds
        fetchMetrics();  // Load data initially
    </script>
</body>
</html>


#app.py

from flask import Flask, jsonify, render_template
from pymongo import MongoClient

app = Flask(__name__)

# Connect to MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client["interaction_db"]
collection = db["aggregations"]

@app.route("/metrics", methods=["GET"])
def get_metrics():
    """Fetch aggregated interaction metrics from MongoDB"""
    data = list(collection.find({}, {"_id": 0}))
    return jsonify(data)

@app.route("/")
def index():
    """Render the real-time dashboard page"""
    return render_template("index.html")

if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5000)

#dashboard.py

import requests

API_URL = "http://localhost:5000/metrics"  # Change from "http://dashboard:5000"

def fetch_data():
    try:
        response = requests.get(API_URL)
        response.raise_for_status()  # Raises an error for HTTP failures
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Failed to fetch data: {e}")
        return {}

if __name__ == "__main__":
    print(fetch_data())

#.gitignore

# .gitignore
__pycache__/
*.log
*.db
*.sqlite
.env
venv/
.DS_Store

#.gitpod.yml

# This configuration file was automatically generated by Gitpod.
# Please adjust to your needs (see https://www.gitpod.io/docs/introduction/learn-gitpod/gitpod-yaml)
# and commit this file to your remote git repository to share the goodness with others.

# Learn more from ready-to-use templates: https://www.gitpod.io/docs/introduction/getting-started/quickstart

tasks:
  - init: pip install -r requirements.txt

#consumer.py

import json
import time
from kafka import KafkaConsumer
from pymongo import MongoClient
from datetime import datetime

KAFKA_TOPIC = "user_interactions"
KAFKA_BROKER = "localhost:9092"
MONGO_URI = "mongodb://localhost:27017/"
MONGO_DB = "interaction_db"
MONGO_COLLECTION = "aggregations"

consumer = KafkaConsumer(
    KAFKA_TOPIC, 
    bootstrap_servers=KAFKA_BROKER, 
    auto_offset_reset='earliest', 
    value_deserializer=lambda v: json.loads(v.decode('utf-8'))
)

client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection = db[MONGO_COLLECTION]

# Dictionary to track user and item-based aggregations
user_aggregations = {}
item_aggregations = {}

# Serial number counter for sequence number
sequence_number = 1

for message in consumer:
    data = message.value
    user_id = data["user_id"]
    item_id = data["item_id"]
    interaction_type = data["interaction_type"]
    interaction_timestamp = data["timestamp"]  # The timestamp of the interaction

    # Add the processed timestamp when the consumer processes the message
    processed_timestamp = int(time.time())  # Current time in seconds since epoch

    # Add sequence number to the interaction
    interaction = {**data, "sequence_number": sequence_number, "processed_timestamp": processed_timestamp}

    # User aggregation: total interactions and unique items
    if user_id not in user_aggregations:
        user_aggregations[user_id] = {
            "total_interactions": 0, 
            "unique_items": set(), 
            "last_interaction_time": 0  # Track the last interaction timestamp
        }
    
    user_aggregations[user_id]["total_interactions"] += 1
    user_aggregations[user_id]["unique_items"].add(item_id)
    user_aggregations[user_id]["last_interaction_time"] = max(user_aggregations[user_id]["last_interaction_time"], interaction_timestamp)

    # Item aggregation: max and min interactions per item
    if item_id not in item_aggregations:
        item_aggregations[item_id] = {
            "max_interactions": 0, 
            "min_interactions": float('inf'), 
            "last_interaction_time": 0  # Track the last interaction timestamp
        }
    
    # Update max/min interactions for items
    item_aggregations[item_id]["max_interactions"] = max(item_aggregations[item_id]["max_interactions"], 1)
    item_aggregations[item_id]["min_interactions"] = min(item_aggregations[item_id]["min_interactions"], 1)
    item_aggregations[item_id]["last_interaction_time"] = max(item_aggregations[item_id]["last_interaction_time"], interaction_timestamp)

    # Update MongoDB with the aggregated data
    collection.update_one(
        {"user_id": user_id},
        {"$set": {
            "total_interactions": user_aggregations[user_id]["total_interactions"],
            "unique_items": list(user_aggregations[user_id]["unique_items"]),
            "last_interaction_time": user_aggregations[user_id]["last_interaction_time"],
            "serial_number": sequence_number,
            "processed_timestamp": processed_timestamp  # Storing processed timestamp in MongoDB
        }},
        upsert=True
    )
    
    collection.update_one(
        {"item_id": item_id},
        {"$set": {
            "max_interactions": item_aggregations[item_id]["max_interactions"],
            "min_interactions": item_aggregations[item_id]["min_interactions"],
            "last_interaction_time": item_aggregations[item_id]["last_interaction_time"],
            "serial_number": sequence_number,
            "processed_timestamp": processed_timestamp  # Storing processed timestamp in MongoDB
        }},
        upsert=True
    )

    # Increment sequence number for the next interaction
    sequence_number += 1

    # Print for debugging
    print(f"Processed interaction {sequence_number - 1}: {interaction}")

#data_genarator.py

import random
import time
import json
from kafka import KafkaProducer
from kafka.errors import KafkaError

KAFKA_TOPIC = "user_interactions"
KAFKA_BROKER = "localhost:9092"

# Adding retries and exception handling
while True:
    try:
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BROKER,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            retries=5
        )
        print("‚úÖ Successfully connected to Kafka")
        break
    except KafkaError as e:
        print(f"‚ùå Failed to connect to Kafka: {e}")
        time.sleep(5)  # Wait before retrying


def generate_interaction():
    return {
        "user_id": random.randint(1, 100),
        "item_id": random.randint(1, 50),
        "interaction_type": random.choice(["click", "view", "purchase"]),
        "timestamp": int(time.time())
    }

while True:
    interaction = generate_interaction()
    try:
        producer.send(KAFKA_TOPIC, interaction)
        print(f"Produced: {interaction}")
    except KafkaError as e:
        print(f"‚ùå Failed to send message: {e}")
    time.sleep(random.uniform(0.5, 2))

#docker-compose.yml

# docker-compose.yml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
    healthcheck:
      test: ["CMD", "kafka-topics", "--list", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      retries: 5
      start_period: 20s
      timeout: 5s

  mongo:
    image: mongo:latest
    ports:
      - "27017:27017"
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      retries: 5
      start_period: 20s
      timeout: 5s
	  
#producel.py

import json
from kafka import KafkaProducer
from data_generator import generate_interaction

KAFKA_TOPIC = "user_interactions"
KAFKA_BROKER = "localhost:9092"
producer = KafkaProducer(bootstrap_servers=KAFKA_BROKER, value_serializer=lambda v: json.dumps(v).encode('utf-8'))

while True:
    producer.send(KAFKA_TOPIC, generate_interaction())
	
#requirements.txt
flask
kafka-python
pymongo
docker

#setup.sh

#!/bin/bash
pip install -r requirements.txt
docker-compose up -d






